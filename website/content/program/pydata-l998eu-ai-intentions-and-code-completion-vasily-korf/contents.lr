_model: session 
---
code: L998EU
---
title: AI Intentions and Code Completion
---
description: Datalore supports intentions – code suggestions based on what you’ve just written.
---
short_description: Datalore supports intentions – code suggestions based on what you’ve just written.
---
twitter_image: /static/media/twitter/L998EU.jpg
---
speakers: Vasily Korf
---
submission_type: Talk
---
domains: Artificial Intelligence, Code-Review, IDEs/ Jupyter, Python
---
biography: #### Vasily Korf

Affiliation: JetBrains



I am a passionate data scientist fascinated by the opportunities created by the abundance of available data and computing power in the modern tech industry. He is convinced that most questions can be answered through data. His research interests lie in data science and machine learning.
---
affiliation: JetBrains
---
track: PyData
---
python_skill: Python Skill Level basic
---
domain_expertise: Domain Expertise some
---
room: Saal 2
---
start_time: 14:35
---
day: wednesday
---
meta_title: AI Intentions and Code Completion Vasily Korf PyConDE & PyDataBerlin 2019 conference 
---
meta_twitter_title: AI Intentions and Code Completion @ #PyConDE #PyDataBerlin #PyData
---
categories: pydata, python-skill-level-basic, domain-expertise-some, talk, artificial-intelligence, code-review, ides-jupyter, python, wednesday, wednesday-1435
---
slugified_slot_links: wednesday, wednesday-1435
---
video_link: https://www.youtube.com/embed/98nyBGXalNg
---
youtube_id: 98nyBGXalNg
---
body: Datalore supports intentions – code suggestions based on what you’ve just written. They cover a wide range of situations from generating code to warnings and optimization suggestions. While Datalore is aware of what intentions can be applied to the particular block of code, it can’t determine which intention will be the most useful for the user and should be shown first. Although Datalore is the web application, we can’t access our users’ source code – and hence can’t match it with intentions they are invoking and use this data for training our model.
As for now, the model architecture follows more or less the same architecture approach, except for using bidirectional LSTM connections.
The current proof-of-concept version obtains up to 57% top-1 accuracy while requiring about 200 ms for one prediction.

