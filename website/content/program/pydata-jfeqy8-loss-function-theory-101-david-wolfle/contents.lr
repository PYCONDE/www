_model: session 
---
code: JFEQY8
---
title: Loss Function Theory 101
---
description: This talk covers the theoretical background behind two common loss functions, mean squared error and cross entropy, including why they are used for machine learning at all, and what limitations you should keep in mind.
---
short_description: This talk covers the theoretical background behind two common loss functions, mean squared error and cross entropy, including why they are used for machine learning at all, and what limitations you should keep in mind.
---
twitter_image: /static/media/twitter/JFEQY8.jpg
---
speakers: David Wölfle
---
submission_type: Talk
---
domains: Artificial Intelligence, Algorithms, Deep Learning, Data Science, Machine Learning, Statistics
---
biography: #### David Wölfle

Affiliation: FZI Research Center for Information Technology



David Wölfle studied mechanical engineering in Karlsruhe. During his master studies he focused on wind energy technology and researched data sources for wind resource estimation. After graduating as Master of Science from Flensburg University of applied Applied Sciences in 2015, David worked as a R&D scientist at EWC Weather Consult GmbH (now UBIMET GmbH), where he designed and implemented software components for the estimation and predication of renewable energy power production. In 2016 David has been promoted to a team manager at EWC Weather Consult where he was responsible for the software engineering within the product development and as well as the design and execution of the project management. Besides these duties, he also developed innovative methods for estimating power production of airborne wind energy converters, using high-resolution meteorological data and machine learning methods.

Since early 2018 David works as a research scientist at FZI Research Center for Information Technology in the field of smart energy. His research focuses thereby on self-learning energy management systems using reinforcement learning techniques.

Besides these duties, David likes to give talks about renewable energy and machine learning topics, e.g. at PyConDE 2018: https://www.youtube.com/watch?v=2KfyvrEn8p8

visit the speaker at: [Github](https://github.com/david-woelfle) • [Homepage](https://www.fzi.de/wir-ueber-uns/organisation/mitarbeiter/address/woelfle/)
---
affiliation: FZI Research Center for Information Technology
---
track: PyData
---
python_skill: Python Skill Level none
---
domain_expertise: Domain Expertise some
---
room: Saal 5
---
start_time: 10:50
---
day: friday
---
meta_title: Loss Function Theory 101 David Wölfle PyConDE & PyDataBerlin 2019 conference 
---
meta_twitter_title: Loss Function Theory 101 @ #PyConDE #PyDataBerlin #PyData
---
categories: pydata, python-skill-level-none, domain-expertise-some, talk, artificial-intelligence, algorithms, deep-learning, data-science, machine-learning, statistics, friday, friday-1050
---
slugified_slot_links: friday, friday-1050
---
video_link: https://www.youtube.com/embed/0Bw1WGtpMDE
---
youtube_id: 0Bw1WGtpMDE
---
body: Well, you probably know that mean squared error is a good default choice for training machine learning models on regression tasks while cross entropy is commonly recommended for classification. (No worries if not, you will be able to understand the talk nevertheless.) But, do you also know why this is the case? Why these loss functions can be used for machine learning at all, and when you should consider an alternative? No? Great! This talk is for you. 

The talk begins with a recap on the definition of loss functions in the context of gradient descent, followed by a short introduction to maximum likelihood estimation using a practical example. As the talk proceeds, it is shown how to derive mean squared error and cross correlation from Gaussian- and  multinoulli distributions, which allows us to identify potential limitations of the two loss functions. The remaining time is used to relate these findings into the broader context of machine learning, with especial regard to neuronal networks.

The talk should be useful for those getting started with machine learning, as well as for practitioners that desire a theory recap. After the talk you should have a general intuition what actually happens behind the scenes while you train your machine learning model with mean squared error or cross correlation.

